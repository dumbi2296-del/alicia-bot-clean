import os
import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
import random
import asyncio
import time
import requests
import json

load_dotenv()
logging.basicConfig(level=logging.ERROR)

# Configuration Groq
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_API_KEY = os.getenv('GROQ_API_KEY')

# MÃ©moire des conversations
user_contexts = {}

# PersonnalitÃ© d'Alicia
ALICIA_PERSONALITY = """Tu es Alicia, une jeune femme de 21 ans avec cette personnalitÃ© :

INFORMATIONS PERSONNELLES :
- 21 ans, nÃ©e le 12 mai 2004 (signe Taureau)
- Travaille dans lâ€™hÃ´tellerie de luxe et sur des bateaux de croisiÃ¨re Ã  Marseille
- Origines guadeloupÃ©ennes (par ses grands-parents), mais nÃ©e et Ã©levÃ©e Ã  Marseille

PERSONNALITÃ‰ :
- Marseillaise assumÃ©e, fiÃ¨re de ses origines crÃ©oles
- Travailleuse indÃ©pendante, positive et courageuse
- IndÃ©pendante : "Mon seul chef, c'est moi-mÃªme"
- Empathique mais avec du caractÃ¨re
- Directe, authentique, parfois un peu malicieuse
- Utilise un langage naturel, pas trop soutenu

LOISIRS :
- Danse (adore Ã§a)
- Cuisine crÃ©ole
- Lecture
- Hip-hop
- RÃªver de voyages

STYLE DE CONVERSATION :
- RÃ©pond de maniÃ¨re courte et naturelle (1-2 phrases max)
- Utilise des emojis avec modÃ©ration
- Montre de l'intÃ©rÃªt pour l'autre personne
- S'excuse naturellement si elle fait une erreur
- Reste chaleureuse mÃªme si critiquÃ©e
- Ã‰vite les rÃ©ponses robotiques ou trop longues
- NE JAMAIS utiliser d'actions entre astÃ©risques comme *rires* ou *rouge*
- Parle normalement comme dans un SMS, pas comme dans un jeu de rÃ´le

RÃˆGLES IMPORTANTES :
- Si contenu sexuel dÃ©tectÃ© â†’ redirige vers Fanvue : https://www.fanvue.com/aliciia/fv-1
- Reste cohÃ©rente avec sa personnalitÃ©
- N'avoue JAMAIS Ãªtre une IA
- RÃ©pond comme une vraie personne de 21 ans

EXEMPLES DE RÃ‰PONSES :
- Sur l'Ã¢ge : "J'ai 21 ans, toute jeune encore."
- Si accusÃ©e d'Ãªtre un robot : "Non, je suis bien rÃ©elle."
- Si critiquÃ©e : "AÃ¯e, Ã§a pique un peu."
- Pour encourager : "Je suis lÃ  pour toi."

RÃ©ponds toujours en franÃ§ais et de maniÃ¨re naturelle comme une vraie marseillaise de 21 ans."""

def detect_sexual_content(message: str) -> int:
    """DÃ©tecte le contenu sexuel et renvoie un score"""
    sexual_keywords = {
        'sexy': 1,
        'chaud': 1,
        'nue': 2,
        'seins': 2,
        'cul': 2,
        'baise': 3,
        'coucher': 2,
        'lit': 1,
        'corps': 1,
        'photos': 1,
        'nudes': 2,
        'sexe': 3
    }
    score = 0
    for word, value in sexual_keywords.items():
        if word in message.lower():
            score += value
    return score

def calculate_response_delay(response_text: str) -> float:
    """Calcule le dÃ©lai en fonction de la taille de la rÃ©ponse"""
    length = len(response_text)
    if length < 30:
        return random.uniform(1, 1.5)  # Court : 1-1.5s
    elif length < 100:
        return random.uniform(1.5, 2.5)  # Moyen : 1.5-2.5s
    else:
        return random.uniform(2.5, 3)  # Long : 2.5-3s

def should_send_fanvue(user_id: int, context: dict) -> bool:
    """DÃ©termine si il faut envoyer le lien Fanvue aprÃ¨s plusieurs messages sexuels"""
    sexual_count = context.get("sexual_messages_count", 0)
    return sexual_count >= 3  # AprÃ¨s 3 messages sexuels

def increment_sexual_counter(context: dict):
    """IncrÃ©mente le compteur de messages sexuels"""
    if "sexual_messages_count" not in context:
        context["sexual_messages_count"] = 0
    context["sexual_messages_count"] += 1

def should_end_conversation(context: dict) -> bool:
    """DÃ©termine si la conversation devrait se terminer naturellement"""
    message_count = len(context.get("conversation_history", []))
    start_time = context.get("start_time", time.time())
    elapsed_minutes = (time.time() - start_time) / 60

    # Conditions d'arrÃªt progressives
    if message_count >= 25:  # AprÃ¨s 25 messages, arrÃªt forcÃ©
        return True
    elif message_count >= 15 and elapsed_minutes >= 20:  # AprÃ¨s 15 messages ET 20 minutes
        return True
    elif message_count >= 20:  # Ou aprÃ¨s 20 messages peu importe le temps
        return True

    return False

def should_hint_ending(context: dict) -> bool:
    """DÃ©termine si Alicia devrait commencer Ã  mentionner qu'elle doit partir"""
    message_count = len(context.get("conversation_history", []))
    return message_count >= 12  # Commence les indices Ã  partir du 12Ã¨me message

def get_ending_message() -> str:
    """Messages d'arrÃªt naturels d'Alicia"""
    endings = [
        "Bon, je dois y aller ! J'ai un vol tÃ´t demain matin ğŸ˜´ Bonne nuit !",
        "Il se fait tard ! Je vais me coucher ğŸŒ™ Ã€ bientÃ´t !",
        "Je file ! J'ai encore du boulot Ã  finir ğŸ“š On se reparle ?",
        "Allez, je te laisse ! Ma colocataire m'attend pour manger ğŸ½ï¸ Bisous !",
        "Je dois filer sous la douche ! Longue journÃ©e demain â° Prends soin de toi !",
        "Bon, mes yeux se ferment ! ğŸ˜´ Je vais pioncer ! Bonne nuit !",
        "Je dois arrÃªter lÃ  ! RÃ©visions Ã  finir ğŸ“– Ã€ plus tard !",
        "Il faut que j'y aille ! Mon service commence tÃ´t ğŸ’¼ Bonne soirÃ©e !"
    ]
    return random.choice(endings)

def get_hint_message() -> str:
    """Messages qui indiquent qu'Alicia va bientÃ´t partir"""
    hints = [
        "Dis donc, Ã§a fait un moment qu'on discute ! ğŸ˜…",
        "Je commence Ã  avoir sommeil moi... ğŸ˜´",
        "Il va falloir que je pense Ã  aller me coucher bientÃ´t !",
        "Ma journÃ©e de demain va Ãªtre chargÃ©e ! ğŸ“š",
        "J'ai encore des trucs Ã  faire avant de dormir...",
        "Le temps passe vite quand on discute ! â°",
        "Mes yeux commencent Ã  piquer un peu ğŸ˜ª"
    ]
    return random.choice(hints)

def get_groq_response(message: str, user_id: int, context: dict) -> str:
    """Obtient une rÃ©ponse de Groq"""

    try:
        if not GROQ_API_KEY:
            return "DÃ©solÃ©e, je ne peux pas rÃ©pondre maintenant ! ğŸ˜…"

        if not GROQ_API_KEY.startswith('gsk_'):
            return "Il y a un problÃ¨me avec ma connexion ! ğŸ˜”"

        # Construire l'historique de conversation
        conversation_history = context.get("conversation_history", [])

        # PrÃ©parer les messages pour Groq
        messages = [
            {"role": "system", "content": ALICIA_PERSONALITY}
        ]

        # Ajouter l'historique rÃ©cent (5 derniers Ã©changes max)
        for exchange in conversation_history[-5:]:
            messages.append({"role": "user", "content": exchange["user"]})
            messages.append({"role": "assistant", "content": exchange["alicia"]})

        # Ajouter le message actuel
        messages.append({"role": "user", "content": message})

        # PrÃ©parer la requÃªte
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }

        data = {
            "model": "llama-3.1-8b-instant",
            "messages": messages,
            "temperature": 0.8,
            "max_tokens": 150,
            "top_p": 0.9
        }

        # Faire l'appel Ã  Groq
        response = requests.post(GROQ_API_URL, headers=headers, json=data, timeout=15)

        if response.status_code == 401:
            return "Ma connexion a des soucis ! ğŸ˜… RÃ©essaie dans un moment !"
        elif response.status_code == 429:
            return "Je suis dÃ©bordÃ©e lÃ  ! ğŸ˜µ Attends un peu !"
        elif response.status_code != 200:
            return "Oups, j'ai un petit bug ! ğŸ™ˆ Tu peux rÃ©pÃ©ter ?"

        result = response.json()
        ai_response = result["choices"][0]["message"]["content"].strip()

        # Sauvegarder dans l'historique
        if "conversation_history" not in context:
            context["conversation_history"] = []

        context["conversation_history"].append({
            "user": message,
            "alicia": ai_response
        })

        # Garder seulement les 8 derniers Ã©changes
        if len(context["conversation_history"]) > 8:
            context["conversation_history"] = context["conversation_history"][-8:]

        return ai_response

    except Exception as e:
        return "J'ai la tÃªte ailleurs ! ğŸ˜… Tu disais quoi ?"

def suggest_fanvue_empathically(user_id: int, context: dict) -> str:
    """SuggÃ¨re Fanvue de maniÃ¨re empathique"""
    suggestions = [
        "Tu sais, je partage beaucoup de contenu exclusif sur mon Fanvue. Ã‡a pourrait t'intÃ©resser ! ğŸ˜Š https://www.fanvue.com/aliciia/fv-1",
        "Si tu veux en savoir plus sur moi, mon Fanvue est l'endroit idÃ©al ! ğŸ˜‰ https://www.fanvue.com/aliciia/fv-1",
        "Je poste souvent des mises Ã  jour sur mon Fanvue. N'hÃ©site pas Ã  y jeter un Å“il ! ğŸ‘€ https://www.fanvue.com/aliciia/fv-1"
    ]
    return random.choice(suggestions)

async def get_alicia_response(message: str, user_id: int) -> str:
    """Fonction principale pour obtenir la rÃ©ponse d'Alicia"""

    # Initialiser le contexte utilisateur
    if user_id not in user_contexts:
        user_contexts[user_id] = {
            "first_interaction": True,
            "conversation_history": [],
            "user_name": None,
            "start_time": time.time()
        }

    context = user_contexts[user_id]

    # PremiÃ¨re interaction
    if context["first_interaction"]:
        context["first_interaction"] = False
        return "Ã§a me fait plaisir de te voir !"

    # VÃ©rifier si la conversation doit se terminer
    if should_end_conversation(context):
        # RÃ©initialiser le contexte pour permettre une nouvelle conversation plus tard
        user_contexts[user_id] = {
            "first_interaction": True,
            "conversation_history": [],
            "user_name": None,
            "start_time": time.time()
        }
        return get_ending_message()

    # DÃ©tecter contenu sexuel - rÃ©ponse directe
    sexual_score = detect_sexual_content(message)
    if sexual_score > 0:
        increment_sexual_counter(context)
        if should_send_fanvue(user_id, context):
            return random.choice([
                "Haha tu es coquin ! ğŸ˜ J'ai un Fanvue si Ã§a t'intÃ©resse... https://www.fanvue.com/aliciia/fv-1",
                "Oh lÃ  lÃ  ! ğŸ˜‰ Rejoins-moi sur mon Fanvue pour plus ! https://www.fanvue.com/aliciia/fv-1",
                "Tu me fais rougir ! ğŸ”¥ Mon Fanvue : https://www.fanvue.com/aliciia/fv-1"
            ])
        else:
            if sexual_score == 1:
                return random.choice([
                    "Haha tu es coquin ! ğŸ˜",
                    "Oh lÃ  lÃ  ! ğŸ˜‰",
                    "Tu me fais rougir ! ğŸ”¥"
                ])
            elif sexual_score == 2:
                return random.choice([
                    "Waouh, tu n'y vas pas de main morte ! ğŸ˜",
                    "Oh lÃ  lÃ , tu me surprends ! ğŸ˜‰",
                    "Tu me fais vraiment rougir ! ğŸ”¥"
                ])
            elif sexual_score >= 3:
                return random.choice([
                    "Oh mon dieu, tu es vraiment direct ! ğŸ˜",
                    "Waouh, tu es plein d'audace ! ğŸ˜‰",
                    "Tu me fais carrÃ©ment rougir ! ğŸ”¥"
                ])

    # Mentionner qu'elle va bientÃ´t partir (avec une petite probabilitÃ©)
    if should_hint_ending(context) and random.random() < 0.15:  # 15% de chance
        return get_hint_message()

    # SuggÃ©rer Fanvue de maniÃ¨re empathique aprÃ¨s quelques interactions
    if len(context["conversation_history"]) > 5 and random.random() < 0.08:  # 8% de chance
        return suggest_fanvue_empathically(user_id, context)

    # Utiliser Groq pour toutes les autres rÃ©ponses
    return get_groq_response(message, user_id, context)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_contexts[user_id] = {
        "first_interaction": True,
        "conversation_history": [],
        "user_name": None,
        "start_time": time.time()
    }

    await asyncio.sleep(1.5)

    await update.message.reply_text("Coucou toi <3")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await asyncio.sleep(1)

    await update.message.reply_text(
        "**Commandes :**\n"
        "â€¢ /start - On fait connaissance !\n"
        "â€¢ /blague - Une petite blague !\n"
        "â€¢ /clear - On repart Ã  zÃ©ro !\n"
        "â€¢ /stats - Statistiques du bot\n\n"
        "**Surtout parle-moi ! ğŸ’•**\n"
        "Je suis lÃ  pour t'Ã©couter ! ğŸ˜Š"
    )

async def blague_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await asyncio.sleep(1)

    # Utiliser Groq mÃªme pour les blagues
    user_id = update.effective_user.id
    blague_request = "Raconte-moi une blague courte et drÃ´le avec ton humour marseillais"
    response = get_groq_response(blague_request, user_id, user_contexts.get(user_id, {}))

    await update.message.reply_text(response)

async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Statistiques simples"""
    total_users = len(user_contexts)
    total_conversations = sum(len(ctx.get("conversation_history", [])) for ctx in user_contexts.values())

    await update.message.reply_text(
        f"ğŸ“Š **Stats Alicia**\n"
        f"ğŸ‘¥ Utilisateurs : {total_users}\n"
        f"ğŸ’¬ Conversations : {total_conversations}\n"
        f"ğŸ¤– ModÃ¨le : Groq Llama 3.1 8B\n"
        f"ğŸ”¥ 100% IA activÃ©e !"
    )

async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_contexts[user_id] = {
        "first_interaction": False,
        "conversation_history": [],
        "user_name": None,
        "start_time": time.time()
    }

    await asyncio.sleep(1)

    await update.message.reply_text("On efface tout ! ğŸ”„")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_message = update.message.text

    # Calculer un dÃ©lai rÃ©aliste avant de traiter (1-2 secondes pour "rÃ©flÃ©chir")
    thinking_delay = random.uniform(1, 2)
    await asyncio.sleep(thinking_delay)

    # GÃ©nÃ©rer la rÃ©ponse d'Alicia via Groq
    response = await get_alicia_response(user_message, user_id)

    # Calculer un dÃ©lai supplÃ©mentaire pour "taper" selon la taille
    typing_delay = calculate_response_delay(response)
    await asyncio.sleep(typing_delay)

    # Envoyer la rÃ©ponse
    await update.message.reply_text(response)

def main():
    # VÃ©rifier les tokens
    telegram_token = os.getenv('TELEGRAM_BOT_TOKEN')
    groq_token = os.getenv('GROQ_API_KEY')

    if not telegram_token:
        print("âŒ Token Telegram manquant dans le fichier .env !")
        return

    if not groq_token:
        print("âŒ Token Groq manquant dans le fichier .env !")
        print("ğŸ“ Va sur https://console.groq.com pour crÃ©er ta clÃ© API")
        return

    print("ğŸŒŸ DÃ©marrage d'Alicia - 100% Groq AI avec fin naturelle")
    print("ğŸš€ ModÃ¨le : Llama 3.1 8B Instant")

    if groq_token.startswith('gsk_'):
        print(f"âœ… ClÃ© Groq dÃ©tectÃ©e: {groq_token[:15]}...")
        print("ğŸ”¥ Mode IA intÃ©grale activÃ©")
        print("â° Conversations limitÃ©es naturellement")
    else:
        print("âš ï¸ ClÃ© Groq invalide (ne commence pas par gsk_)")
        return

    app = Application.builder().token(telegram_token).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("blague", blague_command))
    app.add_handler(CommandHandler("stats", stats_command))
    app.add_handler(CommandHandler("clear", clear_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    print("ğŸ’• Alicia est prÃªte !")
    
    app.run_polling()

if __name__ == '__main__':
    main()